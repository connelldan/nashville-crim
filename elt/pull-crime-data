#!/bin/bash

FILEPATH="elt/data"
FILE="nashvile-crime-data.csv"

# pull data from nashville.gov
wget -O $FILEPATH/$FILE \
"https://data.nashville.gov/api/views/kwnd-qrrm/rows.csv?accessType=DOWNLOAD"

# upload data to gcp bucket
gsutil cp $FILEPATH/$FILE gs://nashville-crime-data

# load raw data to bigquery table as strings
bq --location=US load \
    --skip_leading_rows=1 \
    --source_format=CSV \
    connelld-app-services:nashville_data.crime_temp \
    gs://nashville-crime-data/$FILE \
    Event_Number:STRING,Call_Received:STRING,Complaint_Number:STRING,Tencode:STRING,Tencode_Description:STRING,Tencode_Suffix:STRING,Tencode_Suffix_Description:STRING,Disposition_Code:STRING,Disposition_Description:STRING,Block:STRING,Street_Name:STRING,Unit_Dispatched:STRING,Shift:STRING,Sector:STRING,Zone:STRING,RPA:STRING,Latitude:FLOAT64,Longitude:FLOAT64,Mapped_Location:GEOGRAPHY

# transform string timestamp to new table
bq --location=US query \
--destination_table connelld-app-services:nashville_data.crime \
--use_legacy_sql=false \
--replace \
'select Event_Number, PARSE_TIMESTAMP("%m/%d/%Y %r", Call_Received) as Call_Received,
Complaint_Number, Tencode, Tencode_Description, Tencode_Suffix, Tencode_Suffix_Description, 
Disposition_Code, Disposition_Description, Block, Street_Name, Unit_Dispatched, 
Shift, Sector, Zone, RPA, Latitude, Longitude, Mapped_Location
FROM `connelld-app-services.nashville_data.crime_temp`'

# join crime table to use geo census dims
bq --location=US query \
--destination_table connelld-app-services:nashville_data.crime_census \
--use_legacy_sql=false \
--replace \
'select a.*, b.lsad_name, b.geo_id
from 
`connelld-app-services.nashville_data.crime` a
JOIN 
`bigquery-public-data.geo_census_tracts.census_tracts_tennessee` b
ON 
st_contains(b.tract_geom, a.Mapped_Location)'


# delete temptorary raw table
bq rm -f -t connelld-app-services:nashville_dataset.crime_temp